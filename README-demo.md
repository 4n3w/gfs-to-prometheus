# GFS to Prometheus Demo Environment

This demo environment sets up a complete monitoring stack to visualize your GemFire metrics.

## Quick Start

```bash
# Run the automated setup
./setup-demo.sh /path/to/your/stats.gfs

# Or if you already have processed data:
docker-compose -f docker-compose.example.yml up -d
```

## What's Included

### ðŸ”¥ Prometheus (http://localhost:9090)
- Reads the TSDB data generated by gfs-to-prometheus
- Query interface to explore your GemFire metrics
- Built-in expression browser with auto-completion

### ðŸ“Š Grafana (http://localhost:3000)
- **Login**: admin/admin
- Pre-configured Prometheus datasource
- GemFire Cluster Overview dashboard
- Fully customizable for your specific metrics

### ðŸ“ˆ Node Exporter (http://localhost:9100)  
- System metrics for comparison with GemFire performance
- Demonstrates how GemFire metrics integrate with infrastructure monitoring

## Demo Workflow

### 1. Generate TSDB Data
```bash
# Process your GFS files to create Prometheus TSDB
./gfs-to-prometheus convert your-stats.gfs --tsdb-path ./data

# Or process an entire cluster
./gfs-to-prometheus cluster /var/gemfire/ --cluster-name demo --tsdb-path ./data
```

### 2. Start Monitoring Stack
```bash
docker-compose -f docker-compose.example.yml up -d
```

### 3. Explore in Prometheus UI
Navigate to http://localhost:9090 and try these queries:

```promql
# Find all GemFire metrics
{__name__=~"gemfire.*"}

# Cache operation rates
rate(gemfire_cacheperfstats_gets[5m])
rate(gemfire_cacheperfstats_puts[5m])

# Memory usage by node (if cluster data)
gemfire_vmstats_heapused by (node, node_type)

# Top performing nodes
topk(5, rate(gemfire_cacheperfstats_puts[5m]))
```

### 4. View Cluster Dashboard
Navigate to http://localhost:3000:
1. Login with admin/admin
2. Go to Dashboards â†’ GemFire â†’ Cluster Overview
3. Explore pre-built visualizations

## File Structure

```
demo-environment/
â”œâ”€â”€ docker-compose.example.yml    # Full monitoring stack
â”œâ”€â”€ prometheus.yml                # Prometheus configuration
â”œâ”€â”€ grafana/
â”‚   â”œâ”€â”€ provisioning/
â”‚   â”‚   â”œâ”€â”€ datasources/          # Auto-configure Prometheus
â”‚   â”‚   â””â”€â”€ dashboards/           # Auto-import dashboards
â”‚   â””â”€â”€ dashboards/
â”‚       â””â”€â”€ gemfire-cluster.json  # Pre-built GemFire dashboard
â”œâ”€â”€ data/                         # Your TSDB data (mounted to Prometheus)
â””â”€â”€ setup-demo.sh                 # Automated setup script
```

## Customization

### Add Custom Dashboards
1. Create dashboards in Grafana UI
2. Export as JSON
3. Place in `grafana/dashboards/`
4. Restart Grafana to auto-import

### Modify Prometheus Config
Edit `prometheus.yml` to:
- Add additional scrape targets
- Configure alerting rules
- Adjust retention policies

### Environment Variables
```bash
# Grafana admin password
export GF_SECURITY_ADMIN_PASSWORD=yourpassword

# Prometheus retention
export PROMETHEUS_RETENTION=60d
```

## Integration Testing

This demo serves as an integration test for the converter:

```bash
# Test the full pipeline
./gfs-to-prometheus convert test-data.gfs --tsdb-path ./data
docker-compose -f docker-compose.example.yml up -d

# Verify metrics are queryable
curl "http://localhost:9090/api/v1/query?query=gemfire_cacheperfstats_gets"

# Check dashboard loads
curl -u admin:admin "http://localhost:3000/api/dashboards/uid/gemfire-cluster"
```

## Troubleshooting

### No Metrics Visible
- Check `./data` contains TSDB files
- Verify Prometheus can read the data directory
- Look at Prometheus logs: `docker logs gfs-prometheus`

### Grafana Connection Issues
- Ensure Prometheus is running: `curl http://localhost:9090/-/ready`
- Check datasource configuration in Grafana
- Verify network connectivity between containers

### Performance Issues
- Increase Docker resource limits
- Reduce Prometheus retention period
- Process smaller GFS file samples

## Cleanup

```bash
# Stop all services
docker-compose -f docker-compose.example.yml down

# Remove volumes (optional)
docker-compose -f docker-compose.example.yml down -v

# Clean up data
rm -rf data/
```